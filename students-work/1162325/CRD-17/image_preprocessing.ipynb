{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from commonfunctions import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import math\n",
    "import imutils\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.morphology import binary_erosion, binary_dilation\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Auxilary Functions\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digital_or_not(input_image):\n",
    "    \n",
    "    if '.png' in input_image.lower():\n",
    "        return  1\n",
    "    else:\n",
    "        return  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, factor=1,name=\"image\"):\n",
    "    \"\"\" \n",
    "    show an image until the escape key is pressed\n",
    "    :param factor: scale factor (default 1, half size)\n",
    "    \"\"\"\n",
    "    if factor != 1.0:\n",
    "        img = cv2.resize(img, (0,0), fx=factor, fy=factor) \n",
    "\n",
    "    cv2.imshow(name,img)\n",
    "    while(1):\n",
    "        k = cv2.waitKey(0)\n",
    "        if k==27:    # Esc key to stop\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Image Preprocessing\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(img,gaussian_kernel=5):\n",
    "    \n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.GaussianBlur(img,(gaussian_kernel,gaussian_kernel),0)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mid = 0.5\n",
    "        mean = np.mean(img)\n",
    "        gamma = math.log(mid*255)/math.log(mean)\n",
    "        img = np.power(img, gamma).clip(0,255).astype(np.uint8)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img = cv2.GaussianBlur(img,(gaussian_kernel,gaussian_kernel),0)\n",
    "    \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(img,block_size=25,neighbours=7):\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,block_size,neighbours)\n",
    "    else:\n",
    "        img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,block_size,neighbours)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(im):\n",
    "    max_skew=50\n",
    "    height, width = im.shape\n",
    "    if(height>width):\n",
    "        width = im.shape[0]\n",
    "        height = im.shape[1]\n",
    "        \n",
    "    im_bw = cv2.threshold(im, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    lines = cv2.HoughLinesP(\n",
    "        im_bw, 1, np.pi / 180, 200, minLineLength=width / 3, maxLineGap=width / 100\n",
    "    )\n",
    "    line_image = np.copy(im) * 0 \n",
    "    # Collect the angles of these lines (in radians)\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)    \n",
    "        angles.append(np.arctan2(y2 - y1, x2 - x1))\n",
    "    # If the majority of our lines are vertical, this is probably a landscape image\n",
    "    landscape = np.sum([abs(angle) > np.pi / 4 for angle in angles]) > len(angles) / 2\n",
    "\n",
    "    # Filter the angles to remove outliers based on max_skew\n",
    "    if landscape:\n",
    "        angles = [\n",
    "            angle\n",
    "            for angle in angles\n",
    "            if np.deg2rad(90 - max_skew) < abs(angle) < np.deg2rad(90 + max_skew)\n",
    "        ]\n",
    "    else:\n",
    "        angles = [angle for angle in angles if abs(angle) < np.deg2rad(max_skew)]\n",
    "    \n",
    "    if len(angles) < 5:\n",
    "        # Insufficient data to deskew\n",
    "        return im\n",
    "\n",
    "    # Average the angles to a degree offset\n",
    "    angle_deg = np.rad2deg(np.median(angles))\n",
    "\n",
    "    # If this is landscape image, rotate the entire canvas appropriately\n",
    "    if landscape:\n",
    "        if angle_deg < 0:\n",
    "            im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n",
    "            angle_deg += 90\n",
    "        elif angle_deg > 0:\n",
    "            im = cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            angle_deg -= 90\n",
    "    # Rotate the image by the residual offset\n",
    "    M = cv2.getRotationMatrix2D((width / 2, height / 2), angle_deg, 1)\n",
    "    im = cv2.warpAffine(im, M, (width, height), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphology(img,kernel_size=2):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_size,kernel_size))\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        img = closing\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)      \n",
    "    else:\n",
    "        opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        img = closing\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img,show_steps=0,show_size=1,digital=1):\n",
    "    \n",
    "    if(digital != 1):\n",
    "        gaussian_kernel = 9\n",
    "        block_size = 95\n",
    "        neighbours = 4\n",
    "    else:\n",
    "        gaussian_kernel = 1\n",
    "        block_size = 95\n",
    "        neighbours = 1\n",
    "        \n",
    "\n",
    "    # Gaussian\n",
    "    if(digital != 1):\n",
    "        img = gaussian(img,gaussian_kernel)\n",
    "        if(show_steps !=0 ):\n",
    "            show(img,show_size,\"Gaussian Filtered\")\n",
    "\n",
    "    # local thresh\n",
    "    img = binarize(img,block_size,neighbours)\n",
    "    if(show_steps !=0 ):\n",
    "        show(img,show_size,\"Binarized\")\n",
    "        \n",
    "    # rotate\n",
    "    img = deskew(img)\n",
    "    if(show_steps !=0 ):\n",
    "        show(img,show_size,\"Rotated\")\n",
    "\n",
    "    # morphology to remove noise\n",
    "    if(digital != 1):\n",
    "        img = morphology(img,4)\n",
    "        if(show_steps !=0 ):\n",
    "            show(img,show_size,\"Morphology\")\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Staff Removal\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encoding(img):\n",
    "        \n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "\n",
    "    black_runs = []\n",
    "    white_runs = []\n",
    "    for i in range(cols):        \n",
    "        black_run = 0\n",
    "        white_run = 0\n",
    "\n",
    "        for j in range(rows):\n",
    "            if (img[j][i] == 255 and black_run == 0):\n",
    "                white_run += 1\n",
    "            if (img[j][i] == 0 and white_run != 0):\n",
    "                white_runs.append(white_run)\n",
    "                white_run = 0\n",
    "            if (img[j][i] == 0 and white_run == 0):\n",
    "                black_run += 1\n",
    "            if (img[j][i] == 255 and black_run != 0):\n",
    "                black_runs.append(black_run)\n",
    "                black_run = 0\n",
    "\n",
    "    return white_runs,black_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_run(rle):\n",
    "    \n",
    "    counter = np.zeros(5000)\n",
    "    for i in range(len(rle)):\n",
    "        counter[rle[i]] += 1\n",
    "        \n",
    "    return np.argmax(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines_non_digital(img,staff_thickness,staff_space):\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    \n",
    "    for i in range(cols):\n",
    "        j = 0\n",
    "        while j < rows:\n",
    "            if img[j][i] == 0 and j + staff_thickness < rows:\n",
    "                if np.sum(img[j:j+staff_thickness,i]) != 0:\n",
    "                    img[j:j+staff_thickness,i] = 255\n",
    "            j+=1\n",
    "    kernel = np.ones((staff_thickness+1,2),np.uint8)\n",
    "    img = cv2.erode(img,kernel,iterations = 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_projection(img,show_steps=1,show_size=1):\n",
    "    if(len(img.shape)>2):\n",
    "        img = rgb2gray(img)\n",
    "    proj = np.sum(img,axis=1).astype(int)\n",
    "    \n",
    "    max_line = np.amax(proj)\n",
    "    staffs = proj == (max_line)\n",
    "    m = np.max(proj)\n",
    "    w = 500\n",
    "    result = np.zeros((proj.shape[0],500))\n",
    "\n",
    "    if show_steps == 1 :\n",
    "        for row in range(img.shape[0]):\n",
    "            cv2.line(result, (0,row), (int(proj[row]*w/m),row), (255,255,255), 1)\n",
    "        show(result,show_size,\"Horizontal Projection\")\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_lines(img,show_steps=1,show_size=1):\n",
    "    \"\"\" \n",
    "    Gets horizontal projection and extracts five lines from it\n",
    "    :param\n",
    "    show_steps: wether show steps or not 0 dont show , 1 show\n",
    "    show_size : the size of the shown image a value to factor in x and y\n",
    "    \"\"\"\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inverted = cv2.bitwise_not(img)    \n",
    "    rows_sums = get_horizontal_projection(inverted,show_steps,show_size)\n",
    "    \n",
    "    lines_pixels = []\n",
    "    for i in range(len(rows_sums)):\n",
    "        if rows_sums[i] > img.shape[1]*0.4*255:\n",
    "            lines_pixels.append(i)\n",
    "\n",
    "    lines = []\n",
    "    max_thickness = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines_pixels):\n",
    "        current = lines_pixels[i] - 1\n",
    "        lines.append(lines_pixels[i])\n",
    "        counter = 0\n",
    "        while(lines_pixels[i] == current + 1):\n",
    "            current = lines_pixels[i]\n",
    "            counter += 1\n",
    "            i += 1\n",
    "            if i >= len(lines_pixels):\n",
    "                break\n",
    "        if counter > max_thickness:\n",
    "            max_thickness = counter\n",
    "\n",
    "    return img,lines,max_thickness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines_digital(img,show_steps=1,show_size=1):\n",
    "    _,lines,thickness = identify_lines(img,show_steps,show_size)\n",
    "    test_value = 255*2\n",
    "    pixels_tested = thickness\n",
    "    \n",
    "    for line in lines:\n",
    "        for i in range(2,img.shape[1]-2):\n",
    "            sum_down = 0\n",
    "            for j in range(pixels_tested):\n",
    "                sum_down += img[line+j][i]\n",
    "            if(sum_down < test_value):\n",
    "                img[line][i] = 255\n",
    "                for j in range(pixels_tested):\n",
    "                    img[line+j][i] = 255\n",
    "    \n",
    "    kernel = np.ones((thickness+1,1),np.uint8)\n",
    "    img = cv2.erode(img,kernel,iterations = 1)\n",
    "    return img,lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_staff_lines(img,show_steps=1,show_size=1,digital=1):\n",
    "\n",
    "    white_rle,black_rle = run_length_encoding(img)\n",
    "    staff_thickness = get_common_run(black_rle) + 4\n",
    "    staff_space = get_common_run(white_rle) \n",
    "    _,lines,_ = identify_lines(img,0)\n",
    "    rows = []\n",
    "    i = 0\n",
    "\n",
    "    if(digital ==1):\n",
    "        img,lines = remove_lines_digital(img,show_steps,show_size)\n",
    "        while i < len(lines):\n",
    "            if lines[i]-staff_space*3 < 0 and lines[(4+i)] + staff_space*3 > img.shape[0]:\n",
    "                print(\"A\")\n",
    "                rows.append(img[0:img.shape[0]-1,:])\n",
    "            elif lines[(4+i)] + staff_space*3 > img.shape[0]:\n",
    "                print(\"B\")\n",
    "                print(lines[i]-staff_space*3)\n",
    "                rows.append(img[int(lines[i]-staff_space*3):img.shape[0]-1,:])\n",
    "            elif  lines[i]-staff_space*3 < 0 :\n",
    "                print(\"C\")\n",
    "                rows.append(img[0:lines[(4+i)]+staff_space*3,:])\n",
    "            else:\n",
    "                rows.append(img[int(lines[i]-staff_space*3):int(lines[(4+i)]+staff_space*3),:])\n",
    "            i += 5\n",
    "            \n",
    "    else:\n",
    "        img = remove_lines_non_digital(img,staff_thickness,staff_space)\n",
    "        rows.append(img)\n",
    "    if show_steps == 1 :\n",
    "        for row in rows:\n",
    "            show(row,show_size,\"Removed Lines\")\n",
    "        \n",
    "    return rows,staff_space,staff_thickness,lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Segmentation Part\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(img):\n",
    "    \"\"\" \n",
    "    Segements the notes\n",
    "    :param\n",
    "    img: the img to extract notes from\n",
    "    \"\"\"\n",
    "\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bitwise_not(img)\n",
    "    thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    proj = np.sum(thresh,axis=0)\n",
    "    avg = np.mean(proj)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    started = False\n",
    "    segments = []\n",
    "    for i in range(len(proj)):\n",
    "        if proj[i] > int(avg/50) and started == False:\n",
    "            started = True\n",
    "        if proj[i] < int(avg/50) and started == True:\n",
    "            started = False\n",
    "            end = i\n",
    "            if img[:,start:end] is not None:\n",
    "                segments.append(img[:,start:end])\n",
    "            start = i\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_img(img,digital=1,show_steps=1,show_size=1):\n",
    "    if show_steps == 1 :\n",
    "        show(img,show_size,\"Image Row\")\n",
    "    if digital == 1:\n",
    "        segments = get_notes(img)\n",
    "    else:\n",
    "        segments = better_segment(img)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_segment(img):\n",
    "\n",
    "    original = img.copy()\n",
    "    blurred = cv2.GaussianBlur(img, (1, 1), 0)\n",
    "    canny = cv2.Canny(blurred, 50, 255, 1)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=2)\n",
    "\n",
    "    \n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "    image_number = 0\n",
    "    order_list = []\n",
    "    images = []\n",
    "    area = 0 \n",
    "    for c in cnts:\n",
    "        area += cv2.contourArea(c)\n",
    "    area /= (len(cnts)+5)  \n",
    "    for c in cnts:\n",
    "        if(cv2.contourArea(c) > area):\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            ROI = original[y:y+h, x:x+w]\n",
    "            images.append(ROI)\n",
    "            order_list.append(x+y/1000)\n",
    "            image_number += 1\n",
    "\n",
    "    segments = [x for _,x in sorted(zip(order_list,images))]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Calssification\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_full_symmetry(image):\n",
    "    notImg = cv2.bitwise_not(image)\n",
    "    if notImg is None:\n",
    "        return True\n",
    "    avg = np.sum(notImg)/4\n",
    "    thresh = avg - int(avg/10)\n",
    "    rows = notImg.shape[0]\n",
    "    cols = notImg.shape[1]\n",
    "    q1 = np.sum(notImg[0:int(rows/2),0:int(cols/2)])\n",
    "    q2 = np.sum(notImg[0:int(rows/2),int(cols/2):cols])\n",
    "    q3 = np.sum(notImg[int(rows/2):rows,0:int(cols/2)])\n",
    "    q4 = np.sum(notImg[int(rows/2):rows,int(cols/2):cols])\n",
    "    #print(\"Q1 is \" ,q1, \" and Q2 is \", q2, \" and Q3 is \", q3, \" and Q4 is \", q4)\n",
    "    #print(\"Avg is \", avg)\n",
    "    if q1  >= thresh and q2 >= thresh and q3 >= thresh and q4 >= thresh:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v_lines(img): #This function is for use in classifications only\n",
    "    \n",
    "    gray = img\n",
    "\n",
    "    blur_gray = gray\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 10  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = img.shape[0]-int(img.shape[0]/8)  # minimum number of pixels making up a line\n",
    "    max_line_gap = img.shape[0]-int(img.shape[0]/8)  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "    if lines is None:\n",
    "        return 0\n",
    "    return len(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_half_symmetry(image):\n",
    "    notImg = cv2.bitwise_not(image)\n",
    "    rows = notImg.shape[0]\n",
    "    cols = notImg.shape[1]\n",
    "    topSum =  np.sum(notImg[0:int(rows/2),:])\n",
    "    bottomSum = np.sum(notImg[int(rows/2):rows,: ])\n",
    "    leftSum =np.sum(notImg[:, 0:int(cols/2)])\n",
    "    rightSum = np.sum(notImg[:, int(cols/2): cols]) \n",
    "    topSum = np.int64(topSum)\n",
    "    bottomSum = np.int64(bottomSum)\n",
    "    leftSum = np.int64(leftSum)\n",
    "    rightSum = np.int64(rightSum)\n",
    "    if abs(leftSum - rightSum) <= int(leftSum/10):\n",
    "        \n",
    "        if abs(topSum - bottomSum) > int(bottomSum/5):\n",
    "            return \"double flat\"\n",
    "        else:\n",
    "            return \"natural\"\n",
    "    \n",
    "    else:\n",
    "        return \"flat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_segment(segment):\n",
    "    mask_inv = cv2.bitwise_not(np.copy(segment))\n",
    "    ver_sum = np.sum(mask_inv,axis=1)\n",
    "    v_start = 0\n",
    "    v_end = 0\n",
    "    for i in range(len(ver_sum)):\n",
    "        if(ver_sum[i] > 0 and v_start ==0):\n",
    "            v_start = i\n",
    "        if(ver_sum[i] == 0 and v_start != 0):\n",
    "            v_end = i\n",
    "            break\n",
    "    if(v_end == 0):\n",
    "        v_end = len(ver_sum) - 1\n",
    "    \n",
    "    hor_sum = np.sum(mask_inv,axis=0)\n",
    "    h_start = 0\n",
    "    h_end = 0\n",
    "    for i in range(len(hor_sum)):\n",
    "        if(hor_sum[i] > 0 and h_start ==0):\n",
    "            h_start = i\n",
    "        if(hor_sum[i] == 0 and h_start != 0):\n",
    "            h_end = i\n",
    "            break\n",
    "    if(h_end == 0):\n",
    "        h_end = len(hor_sum) - 1\n",
    "\n",
    "    return segment[v_start:v_end,h_start:h_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoteHead(segment):\n",
    "    rows, cols = segment.shape\n",
    "    for row in rows:\n",
    "        for col in cols:\n",
    "            if (segment[row, shape] == 1):\n",
    "                return row,shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNotes(segment, staff_space, staff_thickness,lines):\n",
    "    croppedSegment = crop_segment(np.copy(segment))\n",
    "    croppedSegment = cv2.bitwise_not(np.copy(croppedSegment)) \n",
    "    mask_inv = cv2.bitwise_not(np.copy(segment))\n",
    "    rows, cols = croppedSegment.shape\n",
    "    \n",
    "    #show(croppedSegment)\n",
    "    topHalf = np.sum(croppedSegment[0:int(rows/2), :])\n",
    "    bottomHalf = np.sum(croppedSegment[int(rows/2):rows, :])\n",
    "    topHalf = np.int64(topHalf)\n",
    "    bottomHalf = np.int64(bottomHalf)\n",
    "    if (topHalf - bottomHalf) > 0:\n",
    "        lines.sort(reverse = True)\n",
    "        for index, line in enumerate(lines):\n",
    "            distance = 0\n",
    "            found = False\n",
    "            if index == 0:\n",
    "                for i in range(line, mask_inv.shape[0] , 1):\n",
    "                    su = np.sum(mask_inv[i])\n",
    "                    if su > 0:\n",
    "                        found = True\n",
    "                        distance += 1\n",
    "                    else:\n",
    "                        break\n",
    "                    if found == False:\n",
    "                        continue\n",
    "                    if abs(distance - staff_space) <= int(staff_space/3):\n",
    "                        return \"b\"\n",
    "            if index == 1:\n",
    "                return None\n",
    "        return None\n",
    "    else:\n",
    "        where = 0\n",
    "        for index, line in enumerate(lines):\n",
    "            if index == 1:\n",
    "                distance = 0\n",
    "                found = False\n",
    "                for i in range(line, lines[index-1] , -1):\n",
    "                    su = np.sum(mask_inv[i])\n",
    "                    if su > 0:\n",
    "                        found = True\n",
    "                        distance += 1\n",
    "                    else:\n",
    "                        break\n",
    "                if found == False:\n",
    "                    continue\n",
    "                if distance < staff_space and distance > int(staff_space/3):\n",
    "                    #print(\"line is \", line)\n",
    "                    #print(\"distance is \",distance,\" and space \", staff_space)\n",
    "                    return \"e\"\n",
    "                elif distance <2 and distance > -2:\n",
    "                    return \"d\"\n",
    "                print(\"line is \", line)\n",
    "            \n",
    "            if index == 2:\n",
    "                distance = 0\n",
    "                found = False\n",
    "                for i in range(line, lines[index-1] , -1):\n",
    "                    su = np.sum(mask_inv[i])\n",
    "                    if su > 0:\n",
    "                        found = True\n",
    "                        distance += 1\n",
    "                    else:\n",
    "                        break\n",
    "                if found == False:\n",
    "                    continue\n",
    "                if distance < staff_space and distance > int(staff_space/3):\n",
    "                    #print(\"line is \", line)\n",
    "                    #print(\"distance is \",distance,\" and space \", staff_space)\n",
    "                    return \"c\"\n",
    "                \n",
    "            if index == 0:\n",
    "                #print(\"index is now 0\")\n",
    "                distance = 0\n",
    "                found = False\n",
    "                for i in range(line, 0, -1):\n",
    "                    su = np.sum(mask_inv[i])\n",
    "                    if su > 0:\n",
    "                        found = True\n",
    "                        distance += 1\n",
    "                    else:\n",
    "                        \n",
    "                        break\n",
    "                if found == False:\n",
    "                    continue\n",
    "                if distance < staff_space and distance > int(staff_space/3):\n",
    "                    #print(\"line is \", line)\n",
    "                    #print(\"distance is \",distance,\" and space \", staff_space)\n",
    "                    return \"g\"\n",
    "                elif abs(distance - staff_space) <= int(staff_space/2):\n",
    "                    #print(\"line is \", line)\n",
    "                    #print(\"distance is \",distance,\" and space \", staff_space)\n",
    "                    return \"a\"\n",
    "                elif distance <2 and distance > -2:\n",
    "                    return \"f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_old(segment, staff_space, staff_thickness,lines):\n",
    "        rows = segment.shape[0]\n",
    "        mask_inv = cv2.bitwise_not(np.copy(segment))\n",
    "        if(np.sum(mask_inv) < 1020):\n",
    "            return None\n",
    "        sum_ver = np.sum(mask_inv,axis=1)\n",
    "        if (np.count_nonzero(sum_ver) >= staff_space*4):\n",
    "            \n",
    "            #TODO: classify note here\n",
    "            note = classifyNotes(segment, staff_space, staff_thickness,lines)\n",
    "            if note == None:\n",
    "                return None\n",
    "            else:\n",
    "                return note\n",
    "\n",
    "        else:\n",
    "            segment = crop_segment(segment)\n",
    "            if (check_full_symmetry(segment)):\n",
    "                if get_v_lines(segment) > 2 :\n",
    "                    return \"#\"\n",
    "                else:\n",
    "                    return \"##\"\n",
    "            else:\n",
    "                classification = check_half_symmetry(segment)\n",
    "                if (classification  == None):\n",
    "                    return None\n",
    "                else:\n",
    "                    return classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DU(segment):\n",
    "    segment = cv2.bitwise_not(np.copy(segment))\n",
    "    ver_sum = np.sum(segment,axis=1)\n",
    "    counter = 0\n",
    "    for i in range(len(ver_sum)):\n",
    "        if ver_sum[i] == 0:\n",
    "            counter+=1\n",
    "        else :\n",
    "            break\n",
    "    return counter\n",
    "def get_ADAU(segment):\n",
    "    segment = crop_segment(segment)\n",
    "    segment = cv2.bitwise_not(np.copy(segment))\n",
    "    AD = np.sum(segment[0:int(segment.shape[0]/2),:])\n",
    "    AU = np.sum(segment[int(segment.shape[0]/2):-1,:])\n",
    "    if AU == 0: \n",
    "        ADAU = 0\n",
    "    else:\n",
    "        ADAU = (AD/AU)\n",
    "    return ADAU\n",
    "def get_ALAR(segment):\n",
    "    segment = crop_segment(segment)\n",
    "    segment = cv2.bitwise_not(np.copy(segment))\n",
    "    AL = np.sum(segment[:,0:int(segment.shape[1]/2)])\n",
    "    AR = np.sum(segment[:,int(segment.shape[1]/2):-1])\n",
    "    if AR == 0: \n",
    "        ALAR = 0\n",
    "    else:\n",
    "        ALAR = (AL/AR)\n",
    "    return ALAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(segments,f,classifier,show_steps=1,show_size=1):\n",
    "    f.write(\"[ \")\n",
    "    \n",
    "    flat = False\n",
    "    double_flat = False\n",
    "    hashtag = False\n",
    "    double_hashtag = False\n",
    "    \n",
    "    for i in range(len(segments)):\n",
    "        mask_inv = cv2.bitwise_not(crop_segment(segments[i]))\n",
    "        if(mask_inv is None):\n",
    "            continue\n",
    "        if show_steps == 1 :\n",
    "            show(segments[i],show_size,\"Segment \"+ str(i+1))\n",
    "        sum_ver = np.sum(mask_inv,axis=1)\n",
    "        sum_hor = np.sum(mask_inv,axis=0)\n",
    "        X_test = np.array([(np.sum(np.count_nonzero(sum_ver))/staff_space)*100,\n",
    "                           (np.sum(np.count_nonzero(sum_hor))/staff_space)*100,\n",
    "                           (get_ADAU(segments[i])/staff_space)*100 ,\n",
    "                           (get_ALAR(segments[i])/staff_space)*100,\n",
    "                           (get_DU(segments[i])/staff_space)*100])\n",
    "        y_pred = classifier.predict([X_test])\n",
    "        if y_pred[0] != \"CLEF\" and y_pred[0] != \"BARLINE\":\n",
    "            if y_pred[0] == \"&\":\n",
    "                flat = True\n",
    "                double_flat = False\n",
    "                hashtag = False\n",
    "                double_hashtag = False\n",
    "            elif y_pred[0] == \"&&\":\n",
    "                flat = False\n",
    "                double_flat = True\n",
    "                hashtag = False\n",
    "                double_hashtag = False                \n",
    "            elif y_pred[0] == \"#\":\n",
    "                flat = False\n",
    "                double_flat = False\n",
    "                hashtag = True\n",
    "                double_hashtag = False\n",
    "            elif y_pred[0] == \"##\":\n",
    "                flat = False\n",
    "                double_flat = False\n",
    "                hashtag = False\n",
    "                double_hashtag = True                \n",
    "            elif y_pred[0] == \"NATURAL\":\n",
    "                pass\n",
    "            elif flat == True:\n",
    "                flat = False\n",
    "                double_flat = False\n",
    "                hashtag = False\n",
    "                double_hashtag = False\n",
    "                temp_str =\"\"\n",
    "                for char in (y_pred[0])[1:]:\n",
    "                    temp_str += char\n",
    "                f.write((y_pred[0])[0]+\"&\"+temp_str+\" \")\n",
    "            elif double_flat == True:\n",
    "                flat = False\n",
    "                double_flat = False\n",
    "                hashtag = False\n",
    "                double_hashtag = False\n",
    "                temp_str =\"\"\n",
    "                for char in (y_pred[0])[1:]:\n",
    "                    temp_str += char\n",
    "                f.write((y_pred[0])[0]+\"&&\"+temp_str+\" \")\n",
    "            elif hashtag == True:\n",
    "                flat = False\n",
    "                double_flat = False\n",
    "                hashtag = False\n",
    "                double_hashtag = False\n",
    "                temp_str =\"\"\n",
    "                for char in (y_pred[0])[1:]:\n",
    "                    temp_str += char\n",
    "                f.write((y_pred[0])[0]+\"#\"+temp_str+\" \")\n",
    "            elif double_hashtag == True:\n",
    "                flat = False\n",
    "                double_flat = False\n",
    "                hashtag = False\n",
    "                double_hashtag = False\n",
    "                temp_str =\"\"\n",
    "                for char in (y_pred[0])[1:]:\n",
    "                    temp_str += char\n",
    "                f.write((y_pred[0])[0]+\"##\"+temp_str+\" \")\n",
    "            else:\n",
    "                f.write(y_pred[0]+\" \")\n",
    "    f.write(\"]\\n\")\n",
    "    f.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_img(img):\n",
    "    img[img<180] = 0\n",
    "    img[img>=180] = 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_KNN(k=3):\n",
    "    url = \"train.csv\"\n",
    "    # Assign colum names to the dataset\n",
    "    names = ['H', 'W', 'ADAU', 'ALAR', 'DU', \"CLASS\"]\n",
    "\n",
    "    # Read dataset to pandas dataframe\n",
    "    dataset = pd.read_csv(url, names=names)\n",
    "    dataset.head()\n",
    "    X = dataset.iloc[1:-1,0:5].values\n",
    "    y = dataset.iloc[1:-1, 5].values\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "    classifier.fit(X, y)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(input_path,input_img):\n",
    "    img = cv2.imread(input_path+input_img)\n",
    "    digital = digital_or_not(input_img)\n",
    "    return img,digital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Main Code\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_steps = 1\n",
    "show_size = 0.4\n",
    "\n",
    "classifier = initialize_KNN()\n",
    "input_path = '/home/kamel/Desktop/Image/Project/OMR_IP/input/'\n",
    "output_path = \"/home/kamel/Desktop/Image/Project/OMR_IP/output/\"\n",
    "images = []\n",
    "for file in os.listdir(input_path):\n",
    "    images.append(file)\n",
    "images.sort()\n",
    "for input_img in images[24:25]:\n",
    "    output_txt = input_img.split(\".\")[0] + \".txt\"\n",
    "    img, digital = read_image(input_path,input_img)\n",
    "    f = open(output_path+output_txt,\"w\")\n",
    "    img = preprocess_img(img,show_steps,show_size,digital)\n",
    "    img = threshold_img(img)\n",
    "    rows,staff_space,staff_thickness,lines = remove_staff_lines(img,show_steps,show_size,digital)\n",
    "    for row in rows:\n",
    "        segments = segment_img(row,digital,show_steps=1,show_size=1)\n",
    "        classify(segments,f,classifier,show_steps,show_size)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Test Area\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "input_path = '/home/kamel/Desktop/Image/Project/OMR_IP/input/'\n",
    "image_name = '01.PNG'\n",
    "img = cv2.imread(input_path+image_name)\n",
    "digital = digital_or_not(image_name)\n",
    "show_steps = 0\n",
    "show_size = 1\n",
    "\n",
    "\n",
    "img = preprocess_img(img,show_steps,show_size,digital)\n",
    "img[img<180] = 0\n",
    "img[img>=180] = 255\n",
    "counter = 0\n",
    "f= open(image_name.split(\".\")[0]+\".csv\",\"w+\")\n",
    "rows,staff_space,staff_thickness,lines = remove_staff_lines(img,show_steps,show_size,digital)\n",
    "for row in rows:\n",
    "    segments = segment_img(row,show_steps,show_size)\n",
    "    for segment in segments:\n",
    "\n",
    "        mask_inv = cv2.bitwise_not(crop_segment(segment))\n",
    "        if(mask_inv is None):\n",
    "            continue\n",
    "        counter += 1\n",
    "#         show(segment,1,str(counter))\n",
    "        sum_ver = np.sum(mask_inv,axis=1)\n",
    "        sum_hor = np.sum(mask_inv,axis=0)\n",
    "\n",
    "#         X_test = np.array([(np.sum(np.count_nonzero(sum_ver))/staff_space)*100,\n",
    "#                            (np.sum(np.count_nonzero(sum_hor))/staff_space)*100,\n",
    "#                            (get_ADAU(segment)/staff_space)*100 ,\n",
    "#                            (get_ALAR(segment)/staff_space)*100,\n",
    "#                            (get_DU(segment)/staff_space)*100])\n",
    "#         y_pred = classifier.predict([X_test])\n",
    "#         print(y_pred)\n",
    "#         print(\"-----------------------------------\")\n",
    "\n",
    "        f.write(str((np.sum(np.count_nonzero(sum_ver))/staff_space)*100)+\",\" +\n",
    "                str((np.sum(np.count_nonzero(sum_hor))/staff_space)*100)+\",\"+\n",
    "                str((get_ADAU(segment)/staff_space)*100) +\",\"+\n",
    "                str((get_ALAR(segment)/staff_space)*100)+\",\"+\n",
    "                str((get_DU(segment)/staff_space)*100) +',\\\"\\\"\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Not Needed\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h_lines(img):\n",
    "    img = cv2.imread('/home/kamel/Desktop/Image/Project/OMR_IP/input/11.jpg')\n",
    "        \n",
    "    gray = preprocess_img(img,0,show_size,0)\n",
    "\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    \n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 500  # minimum number of pixels making up a line\n",
    "    max_line_gap = 500  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "    max_y = []\n",
    "    max_x = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            if(round(slope,1) == -28.8):\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)    \n",
    "            # Draw the lines on the  image\n",
    "    lines_edges = cv2.addWeighted(img, 0.8, line_image, 1, 0)\n",
    "    \n",
    "\n",
    "    return line_image\n",
    "\n",
    "img = get_h_lines(None)\n",
    "show(img,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(img,show_steps=1,show_size=1):\n",
    "    \n",
    "    original = cv2.imread('/home/kamel/Desktop/Image/Project/OMR_IP/input/01.PNG')\n",
    "    if show_steps == 1 : \n",
    "        show(original,show_size,\"TEST\")\n",
    "    img = preprocess_img(original,0,show_size,1)\n",
    "    if show_steps == 1 : \n",
    "        show(img,show_size,\"Blurred\")\n",
    "\n",
    "    canny = cv2.Canny(img, 200, 255, 1)\n",
    "\n",
    "    if show_steps == 1 :\n",
    "        show(canny,show_size,\"Canny\")\n",
    "    kernel = np.ones((25,25),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "    show(dilate,show_size)\n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if len(contours) != 0:\n",
    "        cv2.drawContours(img, contours, -1, 255, 3)\n",
    "        c = max(contours, key = cv2.contourArea)\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "\n",
    "        cv2.drawContours(img,[box],0,(0,0,255),2)\n",
    "        \n",
    "    rows,cols = img.shape[:2]\n",
    "    [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01)\n",
    "    lefty = int((-x*vy/vx) + y)\n",
    "    righty = int(((cols-x)*vy/vx)+y)\n",
    "    cv2.line(img,(cols-1,righty),(0,lefty),(0,255,0),2)        \n",
    "\n",
    "    if show_steps == 1 :\n",
    "        show(img,show_size,\"Contour\")\n",
    "\n",
    "\n",
    "    br = (box[0][0],box[0][1])\n",
    "    bl = (box[1][0],box[1][1])\n",
    "    tl = (box[2][0],box[2][1])\n",
    "    tr = (box[3][0],box[3][1])\n",
    "    \n",
    "    corner_points_array = np.float32([tl,tr,br,bl])    \n",
    "    cv2.circle(original,tl,10,(255,0,0),thickness=7)\n",
    "    cv2.circle(original,tr,10,(255,0,0),thickness=7)\n",
    "    cv2.circle(original,bl,10,(255,0,0),thickness=7)\n",
    "    cv2.circle(original,br,10,(255,0,0),thickness=7)\n",
    "    show(original,show_size,\"The circled\")\n",
    "\n",
    "    width = original.shape[1]\n",
    "    height = original.shape[0]\n",
    "\n",
    "    # Create an array with the parameters (the dimensions) required to build the matrix\n",
    "    imgTl = [0,0]\n",
    "    imgTr = [0,width]\n",
    "    imgBr = [height,width]\n",
    "    imgBl = [height,0]\n",
    "    img_params = np.float32([imgTl,imgTr,imgBr,imgBl])\n",
    "\n",
    "    # Compute and return the transformation matrix\n",
    "    matrix = cv2.getPerspectiveTransform(corner_points_array,img_params)\n",
    "    img_transformed = cv2.warpPerspective(original,matrix,(width,height))\n",
    "\n",
    "    if show_steps == 1 :\n",
    "        show(img_transformed,show_size)\n",
    "    \n",
    "    return img_transformed\n",
    "\n",
    "    \n",
    "# img = get_h_lines(None)\n",
    "# if show_steps == 1 :\n",
    "#     show(img,0.2,\"HLine\")\n",
    "img = rotate_image(None,show_steps=1,show_size=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
