{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import math\n",
    "import imutils\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "from skimage.morphology import binary_erosion, binary_dilation\n",
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Auxilary Functions\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digital_or_not(input_image):\n",
    "    \n",
    "    if '.png' in input_image.lower():\n",
    "        return  1\n",
    "    else:\n",
    "        return  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, factor=1,name=\"image\"):\n",
    "    \"\"\" \n",
    "    show an image until the escape key is pressed\n",
    "    :param factor: scale factor (default 1, half size)\n",
    "    \"\"\"\n",
    "    if factor != 1.0:\n",
    "        img = cv2.resize(img, (0,0), fx=factor, fy=factor) \n",
    "\n",
    "    cv2.imshow(name,img)\n",
    "    while(1):\n",
    "        k = cv2.waitKey(0)\n",
    "        if k==27:    # Esc key to stop\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Image Preprocessing\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(img,gaussian_kernel=5):\n",
    "    \n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.GaussianBlur(img,(gaussian_kernel,gaussian_kernel),0)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mid = 0.5\n",
    "        mean = np.mean(img)\n",
    "        gamma = math.log(mid*255)/math.log(mean)\n",
    "        img = np.power(img, gamma).clip(0,255).astype(np.uint8)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img = cv2.GaussianBlur(img,(gaussian_kernel,gaussian_kernel),0)\n",
    "    \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(im, max_skew=10):\n",
    "\n",
    "    height, width = im.shape\n",
    "\n",
    "    # Create a grayscale image and denoise it\n",
    "\n",
    "    im_gs = cv2.fastNlMeansDenoising(im, h=3)\n",
    "\n",
    "    # Create an inverted B&W copy using Otsu (automatic) thresholding\n",
    "    im_bw = cv2.threshold(im_gs, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Detect lines in this image. Parameters here mostly arrived at by trial and error.\n",
    "    lines = cv2.HoughLinesP(\n",
    "        im_bw, 1, np.pi / 180, 200, minLineLength=width / 12, maxLineGap=width / 150\n",
    "    )\n",
    "\n",
    "    # Collect the angles of these lines (in radians)\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angles.append(np.arctan2(y2 - y1, x2 - x1))\n",
    "\n",
    "    # If the majority of our lines are vertical, this is probably a landscape image\n",
    "    landscape = np.sum([abs(angle) > np.pi / 4 for angle in angles]) > len(angles) / 2\n",
    "\n",
    "    # Filter the angles to remove outliers based on max_skew\n",
    "    if landscape:\n",
    "        angles = [\n",
    "            angle\n",
    "            for angle in angles\n",
    "            if np.deg2rad(90 - max_skew) < abs(angle) < np.deg2rad(90 + max_skew)\n",
    "        ]\n",
    "    else:\n",
    "        angles = [angle for angle in angles if abs(angle) < np.deg2rad(max_skew)]\n",
    "\n",
    "    if len(angles) < 5:\n",
    "        # Insufficient data to deskew\n",
    "        return im\n",
    "\n",
    "    # Average the angles to a degree offset\n",
    "    angle_deg = np.rad2deg(np.median(angles))\n",
    "\n",
    "    # If this is landscape image, rotate the entire canvas appropriately\n",
    "    if landscape:\n",
    "        if angle_deg < 0:\n",
    "            im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n",
    "            angle_deg += 90\n",
    "        elif angle_deg > 0:\n",
    "            im = cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            angle_deg -= 90\n",
    "\n",
    "    # Rotate the image by the residual offset\n",
    "    M = cv2.getRotationMatrix2D((width / 2, height / 2), angle_deg, 1)\n",
    "    im = cv2.warpAffine(im, M, (width, height), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(img,block_size=25,neighbours=7):\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,block_size,neighbours)\n",
    "    else:\n",
    "        img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,block_size,neighbours)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphology(img,kernel_size=2):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_size,kernel_size))\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        img = closing\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)      \n",
    "    else:\n",
    "        opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        img = closing\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img,show_steps=0,show_size=1,digital=1):\n",
    "    \n",
    "    if(digital != 1):\n",
    "#         scale_percent = 45\n",
    "#         width = int(img.shape[1] * scale_percent / 100)\n",
    "#         height = int(img.shape[0] * scale_percent / 100)\n",
    "#         dim = (width, height)\n",
    "#         img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) \n",
    "        gaussian_kernel = 15\n",
    "        block_size = 95\n",
    "        neighbours = 3\n",
    "    else:\n",
    "        gaussian_kernel = 1\n",
    "        block_size = 65\n",
    "        neighbours = 1\n",
    "        \n",
    "\n",
    "    # Gaussian\n",
    "    img = gaussian(img,gaussian_kernel)\n",
    "    if(show_steps !=0 ):\n",
    "        show(img,show_size,\"Gaussian Filtered\")\n",
    "        \n",
    "    # local thresh\n",
    "    img = binarize(img,block_size,neighbours)\n",
    "    if(show_steps !=0 ):\n",
    "        show(img,show_size,\"Binarized\")\n",
    "        \n",
    "#     # rotate\n",
    "#     img = deskew(img)\n",
    "#     if(show_steps !=0 ):\n",
    "#         show(img,show_size,\"Rotated\")\n",
    "\n",
    "    # morphology to remove noise\n",
    "    if(digital != 1):\n",
    "        img = morphology(img,7)\n",
    "        if(show_steps !=0 ):\n",
    "            show(img,show_size,\"Morphology\")\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Staff Removal\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encoding(img):\n",
    "        \n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "\n",
    "    black_runs = []\n",
    "    white_runs = []\n",
    "    for i in range(cols):        \n",
    "        black_run = 0\n",
    "        white_run = 0\n",
    "\n",
    "        for j in range(rows):\n",
    "            if (img[j][i] == 255 and black_run == 0):\n",
    "                white_run += 1\n",
    "            if (img[j][i] == 0 and white_run != 0):\n",
    "                white_runs.append(white_run)\n",
    "                white_run = 0\n",
    "            if (img[j][i] == 0 and white_run == 0):\n",
    "                black_run += 1\n",
    "            if (img[j][i] == 255 and black_run != 0):\n",
    "                black_runs.append(black_run)\n",
    "                black_run = 0\n",
    "\n",
    "    return white_runs,black_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_run(rle):\n",
    "    \n",
    "    counter = np.zeros(5000)\n",
    "    for i in range(len(rle)):\n",
    "        counter[rle[i]] += 1\n",
    "        \n",
    "    return np.argmax(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines_non_digital(img,staff_thickness,staff_space):\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    \n",
    "    for i in range(cols):\n",
    "        j = 0\n",
    "        while j < rows:\n",
    "            if img[j][i] == 0 and j + staff_thickness < rows:\n",
    "                if np.sum(img[j:j+staff_thickness,i]) != 0:\n",
    "                    img[j:j+staff_thickness,i] = 255\n",
    "                    j +=  staff_thickness -1\n",
    "            j+=1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_projection(img,show_steps=1,show_size=1):\n",
    "    if(len(img.shape)>2):\n",
    "        img = rgb2gray(img)\n",
    "    proj = np.sum(img,axis=1).astype(int)\n",
    "    \n",
    "    max_line = np.amax(proj)\n",
    "    staffs = proj == (max_line)\n",
    "    m = np.max(proj)\n",
    "    w = 500\n",
    "    result = np.zeros((proj.shape[0],500))\n",
    "\n",
    "    if show_steps == 1 :\n",
    "        for row in range(img.shape[0]):\n",
    "            cv2.line(result, (0,row), (int(proj[row]*w/m),row), (255,255,255), 1)\n",
    "        show(result,show_size,\"Horizontal Projection\")\n",
    "    return np.argsort(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_lines(img,show_steps=1,show_size=1):\n",
    "    \"\"\" \n",
    "    Gets horizontal projection and extracts five lines from it\n",
    "    :param\n",
    "    show_steps: wether show steps or not 0 dont show , 1 show\n",
    "    show_size : the size of the shown image a value to factor in x and y\n",
    "    \"\"\"\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    staffs = get_horizontal_projection(img,show_steps,show_size)\n",
    "    lines = []\n",
    "    for i in range(len(staffs)):\n",
    "        is_line = True\n",
    "        for j in range(len(lines)):\n",
    "            if(abs(staffs[i] - lines[j]) < int(img.shape[0]/30)):\n",
    "                is_line = False\n",
    "        if(is_line and staffs[i] - 6 > 0 and staffs[i] + 6 < img.shape[0]):\n",
    "            lines.append(staffs[i])\n",
    "        if(len(lines) == 5):\n",
    "            break\n",
    "\n",
    "    return img,lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines_digital(img):\n",
    "    _,lines = identify_lines(img,0)\n",
    "    test_value = 100\n",
    "    pixels_tested = 6\n",
    "    for line in lines:\n",
    "        for i in range(2,img.shape[1]-2):\n",
    "            sum_up = 0\n",
    "            sum_down = 0\n",
    "            for j in range(pixels_tested):\n",
    "                sum_up += img[line-j-1][i]\n",
    "                sum_down += img[line+j][i]\n",
    "            if(sum_up > test_value and sum_down > test_value):\n",
    "                img[line][i] = 255\n",
    "                for j in range(pixels_tested):\n",
    "                    img[line-j][i] = 255\n",
    "                    img[line+j][i] = 255\n",
    "            elif (sum_up > test_value) :\n",
    "                \n",
    "                img[line][i] = 255\n",
    "                for j in range(pixels_tested):\n",
    "                    img[line-j][i] = 255\n",
    "            elif sum_down > test_value:\n",
    "                img[line][i] = 255\n",
    "                for j in range(pixels_tested):\n",
    "                    img[line+j][i] = 255\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img = cv2.erode(img,kernel,iterations = 1)\n",
    "    return img,lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_staff_lines(img,show_steps=1,show_size=1,digital=1):\n",
    "\n",
    "    white_rle,black_rle = run_length_encoding(img)\n",
    "    staff_thickness = get_common_run(black_rle) + 2\n",
    "    staff_space = get_common_run(white_rle) \n",
    "    img,lines = remove_lines_digital(img)\n",
    "#     img = remove_lines_non_digital(img,staff_thickness,staff_space)\n",
    "    if show_steps == 1 :\n",
    "        show(img,show_size,\"Removed Lines\")\n",
    "        \n",
    "    return img,staff_space,staff_thickness,lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Segmentation Part\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(img):\n",
    "    \"\"\" \n",
    "    Segements the notes\n",
    "    :param\n",
    "    img: the img to extract notes from\n",
    "    \"\"\"\n",
    "\n",
    "    if(len(img.shape)>2):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bitwise_not(img)\n",
    "    thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    proj = np.sum(thresh,axis=0)\n",
    "    avg = np.mean(proj)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    started = False\n",
    "    segments = []\n",
    "    for i in range(len(proj)):\n",
    "        if proj[i] > int(avg/10) and started == False:\n",
    "            started = True\n",
    "        if proj[i] < int(avg/10) and started == True:\n",
    "            started = False\n",
    "            end = i\n",
    "            segments.append(img[:,start:end])\n",
    "            start = i\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_img(img,show_steps=1,show_size=1):\n",
    "    segments = get_notes(img)\n",
    "    if show_steps == 1 :\n",
    "        for i in range(len(segments)):\n",
    "            show(segments[i],show_size,\"Segment\")\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_segment(img):\n",
    "\n",
    "    original = img.copy()\n",
    "    blurred = cv2.GaussianBlur(img, (1, 1), 0)\n",
    "    canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=3)\n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "    image_number = 0\n",
    "    order_list = []\n",
    "    images = []\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "        ROI = original[y:y+h, x:x+w]\n",
    "        images.append(ROI)\n",
    "        order_list.append(x)\n",
    "        image_number += 1\n",
    "\n",
    "\n",
    "    segments = [x for _,x in sorted(zip(order_list,images))]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Calssification\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_full_symmetry(image):\n",
    "    notImg = cv2.bitwise_not(image)\n",
    "    avg = np.sum(notImg)/4\n",
    "    thresh = avg - int(avg/10)\n",
    "    rows = notImg.shape[0]\n",
    "    cols = notImg.shape[1]\n",
    "    q1 = np.sum(notImg[0:int(rows/2),0:int(cols/2)])\n",
    "    q2 = np.sum(notImg[0:int(rows/2),int(cols/2):cols])\n",
    "    q3 = np.sum(notImg[int(rows/2):rows,0:int(cols/2)])\n",
    "    q4 = np.sum(notImg[int(rows/2):rows,int(cols/2):cols])\n",
    "    #print(\"Q1 is \" ,q1, \" and Q2 is \", q2, \" and Q3 is \", q3, \" and Q4 is \", q4)\n",
    "    #print(\"Avg is \", avg)\n",
    "    if q1  >= thresh and q2 >= thresh and q3 >= thresh and q4 >= thresh:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v_lines(img): #This function is for use in classifications only\n",
    "    \n",
    "    gray = img\n",
    "\n",
    "    blur_gray = gray\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 10  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = img.shape[0]-int(img.shape[0]/8)  # minimum number of pixels making up a line\n",
    "    max_line_gap = img.shape[0]-int(img.shape[0]/8)  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "    if lines is None:\n",
    "        return 0\n",
    "    return len(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_half_symmetry(image):\n",
    "    notImg = cv2.bitwise_not(image)\n",
    "    rows = notImg.shape[0]\n",
    "    cols = notImg.shape[1]\n",
    "    topSum =  np.sum(notImg[0:int(rows/2),:])\n",
    "    bottomSum = np.sum(notImg[int(rows/2):rows,: ])\n",
    "    leftSum =np.sum(notImg[:, 0:int(cols/2)])\n",
    "    rightSum = np.sum(notImg[:, int(cols/2): cols]) \n",
    "    topSum = np.int64(topSum)\n",
    "    bottomSum = np.int64(bottomSum)\n",
    "    leftSum = np.int64(leftSum)\n",
    "    rightSum = np.int64(rightSum)\n",
    "    if abs(leftSum - rightSum) <= int(leftSum/10):\n",
    "        \n",
    "        if abs(topSum - bottomSum) > int(bottomSum/5):\n",
    "            return \"double flat\"\n",
    "        else:\n",
    "            return \"natural\"\n",
    "    \n",
    "    else:\n",
    "        return \"flat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_segment(segment):\n",
    "    mask_inv = cv2.bitwise_not(np.copy(segment))\n",
    "    ver_sum = np.sum(mask_inv,axis=1)\n",
    "    v_start = 0\n",
    "    v_end = 0\n",
    "    for i in range(len(ver_sum)):\n",
    "        if(ver_sum[i] > 0 and v_start ==0):\n",
    "            v_start = i\n",
    "        if(ver_sum[i] == 0 and v_start != 0):\n",
    "            v_end = i\n",
    "            break\n",
    "    if(v_end == 0):\n",
    "        v_end = len(ver_sum) - 1\n",
    "    \n",
    "    hor_sum = np.sum(mask_inv,axis=0)\n",
    "    h_start = 0\n",
    "    h_end = 0\n",
    "    for i in range(len(hor_sum)):\n",
    "        if(hor_sum[i] > 0 and h_start ==0):\n",
    "            h_start = i\n",
    "        if(hor_sum[i] == 0 and h_start != 0):\n",
    "            h_end = i\n",
    "            break\n",
    "    if(h_end == 0):\n",
    "        h_end = len(hor_sum) - 1\n",
    "\n",
    "    return segment[v_start:v_end,h_start:h_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(segment, line_space):\n",
    "        rows = segment.shape[0]\n",
    "        mask_inv = cv2.bitwise_not(np.copy(segment))\n",
    "        sum_ver = np.sum(mask_inv,axis=1)\n",
    "        if (np.count_nonzero(sum_ver) >= line_space*4):\n",
    "            \n",
    "            #TODO: classify note here\n",
    "            return \"Note\"\n",
    "            pass\n",
    "        else:\n",
    "            segment = crop_segment(segment)\n",
    "            if (check_full_symmetry(segment)):\n",
    "                if get_v_lines(segment) > 1 :\n",
    "                    return \"#\"\n",
    "                else:\n",
    "                    return \"##\"\n",
    "            else:\n",
    "                classification = check_half_symmetry(segment)\n",
    "                if (classification  == None):\n",
    "                    return None\n",
    "                else:\n",
    "                    return classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Main Code\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note\n",
      "Note\n",
      "Note\n",
      "flat\n",
      "Note\n",
      "Note\n",
      "#\n",
      "Note\n",
      "Note\n",
      "Note\n",
      "double flat\n",
      "Note\n",
      "natural\n",
      "Note\n",
      "flat\n",
      "flat\n",
      "Note\n",
      "Note\n",
      "Note\n",
      "Note\n"
     ]
    }
   ],
   "source": [
    "input_image = '/home/kamel/Desktop/Image/Project/OMR_IP/input/02.PNG'\n",
    "img = cv2.imread(input_image) \n",
    "\n",
    "digital = digital_or_not(input_image)\n",
    "show_steps = 1\n",
    "show_size = 1\n",
    "\n",
    "\n",
    "img = preprocess_img(img,show_steps,show_size,digital)\n",
    "img,staff_space,staff_thickness,lines = remove_staff_lines(img,show_steps,show_size)\n",
    "# segments = segment_img(img,show_steps,show_size)\n",
    "segments = segment_img(img,0)\n",
    "for i in range(len(segments)):\n",
    "    show(segments[i],1,\"Segment \" + str(i+1))\n",
    "    print(classify(segments[i], staff_space))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Test Area\n",
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h_lines(img):\n",
    "    img = cv2.imread('/home/kamel/Desktop/Image/Project/OMR_IP/input/05.PNG')\n",
    "        \n",
    "    gray = preprocess_img(img,0,show_size,0)\n",
    "\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    \n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 500  # minimum number of pixels making up a line\n",
    "    max_line_gap = 500  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "    max_y = []\n",
    "    max_x = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)    \n",
    "            # Draw the lines on the  image\n",
    "    lines_edges = cv2.addWeighted(img, 0.8, line_image, 1, 0)\n",
    "    \n",
    "\n",
    "    return line_image\n",
    "\n",
    "img = get_h_lines(None)\n",
    "show(img,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(img,show_steps=1,show_size=1):\n",
    "    \n",
    "    original = cv2.imread('/home/kamel/Desktop/Image/Project/OMR_IP/input/19.jpg')\n",
    "    color = ('b','g','r')\n",
    "#     for i,col in enumerate(color):\n",
    "#         histr = cv2.calcHist([original],[i],None,[256],[0,256])\n",
    "#         plt.plot(histr,color = col)\n",
    "#         plt.xlim([0,256])\n",
    "#     plt.show()\n",
    "    original[original[:,:,0]<120] = 0\n",
    "    original[original[:,:,0]>210] = 0\n",
    "    original[original[:,:,1]<100] = 0\n",
    "    original[original[:,:,1]>210] = 0\n",
    "    original[original[:,:,2]<120] = 0\n",
    "    original[original[:,:,2]>210] = 0\n",
    "\n",
    "    show(original,show_size,\"TEST\")\n",
    "    img = preprocess_img(original,0,show_size,0)\n",
    "    if show_steps == 1 : \n",
    "        show(img,0.2,\"Blurred\")\n",
    "\n",
    "    canny = cv2.Canny(img, 200, 255, 1)\n",
    "\n",
    "    if show_steps == 1 :\n",
    "        show(canny,show_size,\"Canny\")\n",
    "    kernel = np.ones((25,25),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "    show(dilate,show_size)\n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if len(contours) != 0:\n",
    "        cv2.drawContours(img, contours, -1, 255, 3)\n",
    "        c = max(contours, key = cv2.contourArea)\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "\n",
    "        cv2.drawContours(img,[box],0,(0,0,255),2)\n",
    "        \n",
    "    rows,cols = img.shape[:2]\n",
    "    [vx,vy,x,y] = cv2.fitLine(c, cv2.DIST_L2,0,0.01,0.01)\n",
    "    lefty = int((-x*vy/vx) + y)\n",
    "    righty = int(((cols-x)*vy/vx)+y)\n",
    "    cv2.line(img,(cols-1,righty),(0,lefty),(0,255,0),2)        \n",
    "\n",
    "    if show_steps == 1 :\n",
    "        show(img,show_size,\"Contour\")\n",
    "\n",
    "    tr = (box[3][0],box[3][1])\n",
    "    tl = (box[0][0],box[0][1])\n",
    "    bl = (box[1][0],box[1][1])\n",
    "    br = (box[2][0],box[2][1])\n",
    "\n",
    "    corner_points_array = np.float32([tl,tr,br,bl])    \n",
    "    cv2.circle(original,tl,10,(255,255,0),thickness=7)\n",
    "    cv2.circle(original,tr,10,(255,255,0),thickness=7)\n",
    "    cv2.circle(original,bl,10,(255,255,0),thickness=7)\n",
    "    cv2.circle(original,br,10,(255,255,0),thickness=7)\n",
    "    show(original,show_size,\"The circled\")\n",
    "\n",
    "    width = original.shape[0]\n",
    "    height = original.shape[1]\n",
    "\n",
    "    # Create an array with the parameters (the dimensions) required to build the matrix\n",
    "    imgTl = [0,0]\n",
    "    imgTr = [0,width]\n",
    "    imgBr = [height,width]\n",
    "    imgBl = [height,0]\n",
    "    img_params = np.float32([imgTl,imgTr,imgBr,imgBl])\n",
    "\n",
    "    # Compute and return the transformation matrix\n",
    "    matrix = cv2.getPerspectiveTransform(corner_points_array,img_params)\n",
    "    img_transformed = cv2.warpPerspective(original,matrix,(width,height))\n",
    "\n",
    "    if show_steps == 1 :\n",
    "        show(img_transformed,show_size)\n",
    "    \n",
    "    return img_transformed\n",
    "\n",
    "    \n",
    "# img = get_h_lines(None)\n",
    "# if show_steps == 1 :\n",
    "#     show(img,0.2,\"HLine\")\n",
    "img = rotate_image(None,show_steps=1,show_size=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "# Not Needed\n",
    "## -----------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
